# ğŸ“‹ Phase 2-4 å¯¦æ–½è©³ç´°è¨ˆåŠƒ

> **åŸºæ–¼**ï¼šCOMPREHENSIVE_FUZZY_ANALYSIS.md
> **å‰µå»ºæ—¥æœŸ**ï¼š2025-12-08
> **Phase 1 å®Œæˆç‹€æ…‹**ï¼šâœ… 4å€‹ä»»å‹™å…¨éƒ¨å®Œæˆ
> **é ä¼°ç¸½å·¥æ™‚**ï¼š3-4é€±

---

## âœ… Phase 1 å®Œæˆç¸½çµ

**å®Œæˆæ—¥æœŸ**ï¼š2025-12-08
**å®Œæˆä»»å‹™**ï¼š
- âœ… Task 1: ä¿®å¾©ä¸­æ–‡å»¶é²å°å…¥bug (5åˆ†é˜)
- âœ… Task 2: æ·»åŠ ä¸­æ–‡ç¬›å¡çˆ¾ç©ä¸Šé™ (3å°æ™‚)
- âœ… Task 3: ä¿®å¾©è‹±æ–‡æ’åºç©©å®šæ€§ (3å°æ™‚)
- âœ… Task 4: å¯¦ç¾æ—¥æ–‡èªéŸ³keyæ­£è¦åŒ– (1å¤©)

**æˆæœ**ï¼š
- ä¿®å¾©äº†1å€‹çœŸå¯¦bugï¼ˆå»¶é²å°å…¥ï¼‰
- é˜²æ­¢ä¸­æ–‡é•·è©å¡æ­»ï¼ˆç¬›å¡çˆ¾ç©çˆ†ç‚¸ï¼‰
- ç¢ºä¿è‹±æ–‡è¼¸å‡ºç¢ºå®šæ€§ï¼ˆç©©å®šæ’åºï¼‰
- å¯¦ç¾æ—¥æ–‡å‡åå±¤ç´šé•·éŸ³/ä¿ƒéŸ³æ­£è¦åŒ–

---

## ğŸ¯ Phase 2: è‹±æ–‡ IPA é‡æ§‹ï¼ˆ1-2é€±ï¼‰

### ğŸ“Œ æ ¸å¿ƒç›®æ¨™

**å°‡è‹±æ–‡æ¨¡çµ„å¾ã€Œç¡¬ç·¨ç¢¼è¦å‰‡ã€è½‰æ›ç‚ºã€ŒåŸºæ–¼IPAçš„èªéŸ³ç¶­åº¦ç”Ÿæˆã€**

**ç•¶å‰å•é¡Œ**ï¼š
- âŒ Docstringè²ç¨± "å¾IPAéŸ³æ¨™åæ¨"ï¼Œä½†å¯¦éš›æœªå¯¦ç¾
- âŒ åƒ…ä½¿ç”¨ç¡¬ç·¨ç¢¼è¦å‰‡ï¼ˆASR_SPLIT_PATTERNS, SPELLING_PATTERNSï¼‰
- âŒ ç„¡æ³•æ³›åŒ–åˆ°æ–°è©ï¼ˆå¦‚ "Ollama", "LangChain"ï¼‰
- âŒ é•èƒŒã€ŒèªéŸ³ç¶­åº¦ã€æ ¸å¿ƒç†å¿µï¼ˆç¬¦åˆåº¦åƒ…33%ï¼‰

**ç›®æ¨™æ¶æ§‹**ï¼š
```
Term â†’ IPA â†’ Fuzzy IPA Variants â†’ Possible Spellings â†’ Deduplication
```

---

### ğŸ“… è©³ç´°ä»»å‹™åˆ†è§£

#### Task 5.1: å»ºç«‹ IPA éŸ³ç´ æ¨¡ç³Šè¦å‰‡ç³»çµ±ï¼ˆ2å¤©ï¼‰

**æ–‡ä»¶**ï¼š`src/phonofix/languages/english/config.py`

**ä»»å‹™æè¿°**ï¼š
1. ç ”ç©¶å¸¸è¦‹ ASR éŸ³ç´ æ··æ·†æ¨¡å¼
2. å®šç¾© IPA æ¨¡ç³Šè¦å‰‡é…ç½®
3. å¯¦ç¾éŸ³ç´ æ›¿æ›é‚è¼¯

**æ–°å¢é…ç½®é …**ï¼š
```python
# src/phonofix/languages/english/config.py

class EnglishPhoneticConfig:
    """
    è‹±æ–‡èªéŸ³é…ç½®ï¼ˆåŸºæ–¼ IPAï¼‰
    """

    # IPA æ¸…æ¿éŸ³æ··æ·†
    IPA_VOICING_CONFUSIONS = [
        ('p', 'b'),   # pit â†” bit
        ('t', 'd'),   # ten â†” den
        ('k', 'É¡'),   # cap â†” gap
        ('f', 'v'),   # fan â†” van
        ('s', 'z'),   # seal â†” zeal
        ('Î¸', 'Ã°'),   # think â†” this
        ('Êƒ', 'Ê’'),   # mesh â†” measure
    ]

    # IPA é•·çŸ­å…ƒéŸ³æ··æ·†
    IPA_VOWEL_LENGTH_CONFUSIONS = [
        ('iË', 'Éª'),  # sheep â†” ship
        ('uË', 'ÊŠ'),  # pool â†” pull
        ('É”Ë', 'É’'),  # bought â†” bot (UK)
        ('É‘Ë', 'Ã¦'),  # bath â†” bat (UK vs US)
    ]

    # IPA ç›¸ä¼¼éŸ³ç´ æ··æ·†
    IPA_SIMILAR_PHONE_CONFUSIONS = [
        ('Î¸', 'f'),   # think â†’ fink
        ('Ã°', 'v'),   # this â†’ vis
        ('r', 'l'),   # rice â†” lice (L2 speakers)
        ('n', 'm'),   # é¼»éŸ³æ··æ·†
        ('Å‹', 'n'),   # sing â†” sin
    ]

    # IPA éŸ³ç¯€ç°¡åŒ–è¦å‰‡
    IPA_REDUCTION_RULES = [
        ('É™', ''),    # schwa deletion
        ('tÌ¬', 'd'),   # flapping (water â†’ wader)
        ('kw', 'k'),  # éŸ³ç¯€ç°¡åŒ–
    ]
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] é…ç½®æ–‡ä»¶åŒ…å«è‡³å°‘ 20 æ¢éŸ³ç´ è¦å‰‡
- [ ] è¦å‰‡æ¶µè“‹æ¸…æ¿éŸ³ã€é•·çŸ­éŸ³ã€ç›¸ä¼¼éŸ³ã€ç°¡åŒ–éŸ³
- [ ] æ¯æ¢è¦å‰‡æœ‰å¯¦éš›ç¯„ä¾‹è¨»é‡‹

---

#### Task 5.2: å¯¦ç¾ IPA è®Šé«”ç”Ÿæˆå™¨ï¼ˆ3å¤©ï¼‰

**æ–‡ä»¶**ï¼š`src/phonofix/languages/english/fuzzy_generator.py`

**ä»»å‹™æè¿°**ï¼š
1. æ·»åŠ  `_generate_ipa_fuzzy_variants()` æ–¹æ³•
2. æ‡‰ç”¨éŸ³ç´ è¦å‰‡ç”Ÿæˆè®Šé«”
3. å¯¦ç¾ Levenshtein è·é›¢éæ¿¾

**æ–°å¢æ–¹æ³•**ï¼š
```python
class EnglishFuzzyGenerator:

    def _generate_ipa_fuzzy_variants(self, ipa: str) -> List[str]:
        """
        åŸºæ–¼ IPA éŸ³ç´ è¦å‰‡ç”Ÿæˆæ¨¡ç³Šè®Šé«”

        Args:
            ipa: IPA éŸ³æ¨™å­—ä¸²ï¼ˆå¦‚ "ËˆpaÉªÎ¸É‘n"ï¼‰

        Returns:
            List[str]: IPA è®Šé«”åˆ—è¡¨
        """
        variants = {ipa}

        # 1. æ‡‰ç”¨æ¸…æ¿éŸ³æ··æ·†
        for s1, s2 in self.config.IPA_VOICING_CONFUSIONS:
            if s1 in ipa:
                variants.add(ipa.replace(s1, s2))
            if s2 in ipa:
                variants.add(ipa.replace(s2, s1))

        # 2. æ‡‰ç”¨é•·çŸ­å…ƒéŸ³æ··æ·†
        for long_v, short_v in self.config.IPA_VOWEL_LENGTH_CONFUSIONS:
            if long_v in ipa:
                variants.add(ipa.replace(long_v, short_v))
            if short_v in ipa:
                variants.add(ipa.replace(short_v, long_v))

        # 3. æ‡‰ç”¨ç›¸ä¼¼éŸ³ç´ æ··æ·†
        for p1, p2 in self.config.IPA_SIMILAR_PHONE_CONFUSIONS:
            if p1 in ipa:
                variants.add(ipa.replace(p1, p2))
            if p2 in ipa:
                variants.add(ipa.replace(p2, p1))

        # 4. æ‡‰ç”¨éŸ³ç¯€ç°¡åŒ–
        for full, reduced in self.config.IPA_REDUCTION_RULES:
            if full in ipa:
                variants.add(ipa.replace(full, reduced))

        return list(variants)
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] èƒ½ç‚ºå–®å€‹ IPA ç”Ÿæˆ 5-20 å€‹è®Šé«”
- [ ] è®Šé«”è¦†è“‹æ‰€æœ‰é…ç½®çš„è¦å‰‡é¡å‹
- [ ] é€šéå–®å…ƒæ¸¬è©¦ï¼ˆå¦‚ "ËˆpaÉªÎ¸É‘n" â†’ "ËˆpaÉªfÉ‘n", "ËˆbaÉªÎ¸É‘n" ç­‰ï¼‰

---

#### Task 5.3: å¯¦ç¾ IPA â†’ æ‹¼å¯«åæŸ¥ï¼ˆ4å¤©ï¼‰â­

**æ–‡ä»¶**ï¼š`src/phonofix/languages/english/ipa_to_spelling.py`ï¼ˆæ–°å»ºï¼‰

**ä»»å‹™æè¿°**ï¼š
1. æ•´åˆ CMU Pronouncing Dictionary
2. å¯¦ç¾ IPA â†’ æ‹¼å¯«æ˜ å°„
3. è™•ç†ä¸€éŸ³å¤šå­—æƒ…æ³

**æ–°å¢æ¨¡çµ„**ï¼š
```python
# src/phonofix/languages/english/ipa_to_spelling.py

from typing import List, Dict
import re

class IPAToSpellingMapper:
    """
    IPA éŸ³æ¨™åˆ°æ‹¼å¯«çš„åå‘æ˜ å°„

    ä½¿ç”¨ç­–ç•¥ï¼š
    1. CMU Pronouncing Dictionaryï¼ˆä¸»è¦ï¼‰
    2. éŸ³ç´ â†’å­—æ¯è¦å‰‡æ˜ å°„ï¼ˆè£œå……ï¼‰
    """

    def __init__(self):
        self._cmu_dict = self._load_cmu_dict()
        self._ipa_to_grapheme_rules = self._build_ipa_grapheme_rules()

    def _load_cmu_dict(self) -> Dict[str, List[str]]:
        """
        è¼‰å…¥ CMU ç™¼éŸ³å­—å…¸

        Returns:
            Dict[IPA, List[spelling]]: IPA â†’ å¯èƒ½æ‹¼å¯«åˆ—è¡¨
        """
        # TODO: è¼‰å…¥ CMUdictï¼Œè½‰æ›ç‚º IPA ç´¢å¼•
        # ä½¿ç”¨ eng_to_ipa æˆ– phonemizer
        return {}

    def _build_ipa_grapheme_rules(self) -> Dict[str, List[str]]:
        """
        å»ºç«‹ IPA éŸ³ç´  â†’ å­—æ¯çµ„åˆçš„è¦å‰‡

        Returns:
            Dict[IPA, List[grapheme]]: éŸ³ç´  â†’ å¯èƒ½å­—æ¯çµ„åˆ
        """
        return {
            'Î¸': ['th'],
            'Ã°': ['th'],
            'Êƒ': ['sh', 'ti', 'ci'],
            'Ê’': ['s', 'si', 'zi'],
            'tÊƒ': ['ch', 'tch'],
            'dÊ’': ['j', 'g', 'dge'],
            'Å‹': ['ng', 'n'],
            'iË': ['ee', 'ea', 'e', 'ie'],
            'eÉª': ['ay', 'ai', 'a_e', 'ey'],
            # ... æ›´å¤šè¦å‰‡
        }

    def ipa_to_spellings(self, ipa: str, max_results: int = 10) -> List[str]:
        """
        å°‡ IPA è½‰æ›ç‚ºå¯èƒ½çš„æ‹¼å¯«

        Args:
            ipa: IPA éŸ³æ¨™
            max_results: æœ€å¤šè¿”å›å¹¾å€‹æ‹¼å¯«

        Returns:
            List[str]: å¯èƒ½çš„æ‹¼å¯«åˆ—è¡¨
        """
        spellings = []

        # 1. å¾ CMU å­—å…¸æŸ¥è©¢
        if ipa in self._cmu_dict:
            spellings.extend(self._cmu_dict[ipa][:max_results])

        # 2. ä½¿ç”¨éŸ³ç´ â†’å­—æ¯è¦å‰‡ç”Ÿæˆ
        if len(spellings) < max_results:
            rule_based = self._apply_grapheme_rules(ipa)
            spellings.extend(rule_based[:max_results - len(spellings)])

        return spellings[:max_results]

    def _apply_grapheme_rules(self, ipa: str) -> List[str]:
        """æ‡‰ç”¨éŸ³ç´ â†’å­—æ¯è¦å‰‡"""
        # ç°¡åŒ–å¯¦ç¾ï¼šé€å€‹éŸ³ç´ æ›¿æ›
        result = ipa
        for phone, graphemes in self._ipa_to_grapheme_rules.items():
            if phone in result:
                # é¸æ“‡æœ€å¸¸è¦‹çš„å­—æ¯çµ„åˆ
                result = result.replace(phone, graphemes[0])

        return [result]
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] æ•´åˆ CMU Pronouncing Dictionaryï¼ˆæˆ–ä½¿ç”¨ phonemizerï¼‰
- [ ] å°æ–¼å¸¸è¦‹è©ï¼Œèƒ½åæŸ¥å‡ºæ­£ç¢ºæ‹¼å¯«ï¼ˆå¦‚ "ËˆpaÉªÎ¸É‘n" â†’ "python"ï¼‰
- [ ] å°æ–¼ç”Ÿåƒ»è©ï¼Œèƒ½åŸºæ–¼è¦å‰‡ç”Ÿæˆåˆç†è¿‘ä¼¼æ‹¼å¯«
- [ ] é€šé 20+ å€‹æ¸¬è©¦æ¡ˆä¾‹

---

#### Task 5.4: é‡æ§‹ `generate_variants()` ä¸»æµç¨‹ï¼ˆ2å¤©ï¼‰

**æ–‡ä»¶**ï¼š`src/phonofix/languages/english/fuzzy_generator.py`

**ä»»å‹™æè¿°**ï¼š
1. é‡æ§‹ä¸»æ–¹æ³•ï¼Œæ•´åˆ IPA æµç¨‹
2. ä¿ç•™ç¡¬ç·¨ç¢¼è¦å‰‡ä½œç‚ºè£œå……
3. å¯¦ç¾åŸºæ–¼ IPA çš„å»é‡

**é‡æ§‹å¾Œçš„ä¸»æ–¹æ³•**ï¼š
```python
class EnglishFuzzyGenerator:

    def __init__(self, config=None):
        self.config = config or EnglishPhoneticConfig()
        self.phonetic = EnglishPhoneticSystem()  # ä½¿ç”¨ç¾æœ‰çš„ IPA backend
        self.ipa_mapper = IPAToSpellingMapper()

    def generate_variants(self, term: str, max_variants: int = 30) -> List[str]:
        """
        åŸºæ–¼ IPA çš„è®Šé«”ç”Ÿæˆï¼ˆé‡æ§‹ç‰ˆï¼‰

        ç­–ç•¥ï¼š
        1. IPA ç¶­åº¦ç”Ÿæˆï¼ˆä¸»è¦ï¼‰
        2. ç¡¬ç·¨ç¢¼è¦å‰‡ï¼ˆè£œå……ï¼‰
        3. åŸºæ–¼ IPA å»é‡
        """
        all_variants = {}  # Dict[str, str]ï¼š{spelling: ipa}

        # ========== æ–¹æ³• 1: IPA ç¶­åº¦ç”Ÿæˆ ==========
        try:
            base_ipa = self.phonetic.to_phonetic(term)

            # ç”Ÿæˆ IPA è®Šé«”
            ipa_variants = self._generate_ipa_fuzzy_variants(base_ipa)

            # IPA â†’ æ‹¼å¯«åæŸ¥
            for ipa_var in ipa_variants:
                spellings = self.ipa_mapper.ipa_to_spellings(ipa_var, max_results=5)
                for spelling in spellings:
                    if spelling not in all_variants:
                        all_variants[spelling] = ipa_var

        except Exception as e:
            # IPA ç”Ÿæˆå¤±æ•—æ™‚é™ç´šåˆ°è¦å‰‡æ¨¡å¼
            logger.warning(f"IPA generation failed for '{term}': {e}")

        # ========== æ–¹æ³• 2: ç¡¬ç·¨ç¢¼è¦å‰‡ï¼ˆè£œå……ï¼‰==========
        # ä¿ç•™ç¾æœ‰çš„ ASR_SPLIT_PATTERNSã€SPELLING_PATTERNS ç­‰
        pattern_variants = self._apply_asr_patterns(term)
        for variant in pattern_variants:
            if variant not in all_variants:
                # è¨ˆç®—è®Šé«”çš„ IPA ç”¨æ–¼å»é‡
                try:
                    variant_ipa = self.phonetic.to_phonetic(variant)
                    all_variants[variant] = variant_ipa
                except:
                    all_variants[variant] = ""  # ç„¡æ³•ç²å– IPAï¼Œä¿ç•™æ‹¼å¯«

        # ========== å»é‡èˆ‡éæ¿¾ ==========
        # ç§»é™¤åŸè©
        all_variants.pop(term, None)
        all_variants.pop(term.lower(), None)

        # åŸºæ–¼ IPA å»é‡ï¼ˆphonetic key ç›¸åŒçš„åªä¿ç•™ç¬¬ä¸€å€‹ï¼‰
        unique_variants = self._deduplicate_by_ipa(all_variants)

        # åŸºæ–¼ IPA è·é›¢éæ¿¾
        filtered = self._filter_by_ipa_distance(term, unique_variants)

        # ç©©å®šæ’åºï¼ˆæŒ‰å­—æ¯é †åºï¼‰
        sorted_variants = sorted(filtered)

        return sorted_variants[:max_variants]

    def _deduplicate_by_ipa(self, variants: Dict[str, str]) -> List[str]:
        """åŸºæ–¼ IPA phonetic key å»é‡"""
        seen_ipa = set()
        unique = []

        for spelling, ipa in variants.items():
            if ipa and ipa not in seen_ipa:
                unique.append(spelling)
                seen_ipa.add(ipa)
            elif not ipa:  # IPA ç¼ºå¤±ï¼Œä¿ç•™æ‹¼å¯«
                unique.append(spelling)

        return unique

    def _filter_by_ipa_distance(self, original: str, variants: List[str]) -> List[str]:
        """åŸºæ–¼ IPA ç·¨è¼¯è·é›¢éæ¿¾"""
        try:
            original_ipa = self.phonetic.to_phonetic(original)
        except:
            return variants  # ç„¡æ³•ç²å– IPAï¼Œè·³ééæ¿¾

        filtered = []

        for variant in variants:
            try:
                variant_ipa = self.phonetic.to_phonetic(variant)

                # å‹•æ…‹é–¾å€¼ï¼šæ ¹æ“š IPA é•·åº¦
                ipa_len = len(original_ipa)
                threshold = max(2, int(ipa_len * 0.35))

                dist = Levenshtein.distance(original_ipa, variant_ipa)

                if dist <= threshold:
                    filtered.append(variant)
            except:
                # ç„¡æ³•ç²å– IPAï¼Œä¿ç•™è®Šé«”
                filtered.append(variant)

        return filtered

    def _apply_asr_patterns(self, term: str) -> List[str]:
        """æ‡‰ç”¨ç¾æœ‰ç¡¬ç·¨ç¢¼è¦å‰‡ï¼ˆä¿ç•™ï¼‰"""
        # ä¿ç•™ç¾æœ‰çš„ _generate_full_word_variants()
        # _generate_acronym_variants()
        # _generate_compound_variants()
        # _apply_spelling_patterns()
        # ç­‰æ–¹æ³•ï¼Œä¸åšä¿®æ”¹
        pass
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] ä¸»æµç¨‹å®Œæ•´å¯¦ç¾ã€ŒTerm â†’ IPA â†’ Fuzzy IPA â†’ Spellingsã€
- [ ] ç¡¬ç·¨ç¢¼è¦å‰‡ä½œç‚ºè£œå……ä¿ç•™
- [ ] åŸºæ–¼ IPA phonetic key æ­£ç¢ºå»é‡
- [ ] åŸºæ–¼ IPA è·é›¢æ­£ç¢ºéæ¿¾
- [ ] é€šéæ‰€æœ‰ç¾æœ‰æ¸¬è©¦ + æ–°å¢ IPA æ¸¬è©¦

---

#### Task 5.5: æ¸¬è©¦èˆ‡é©—è­‰ï¼ˆ2å¤©ï¼‰

**æ–‡ä»¶**ï¼š`tests/test_english_fuzzy_ipa.py`ï¼ˆæ–°å»ºï¼‰

**ä»»å‹™æè¿°**ï¼š
1. ç·¨å¯« IPA è®Šé«”ç”Ÿæˆæ¸¬è©¦
2. é©—è­‰æ–°è©æ³›åŒ–èƒ½åŠ›
3. æ€§èƒ½æ¸¬è©¦

**æ¸¬è©¦æ¡ˆä¾‹**ï¼š
```python
# tests/test_english_fuzzy_ipa.py

import pytest
from phonofix.languages.english.fuzzy_generator import EnglishFuzzyGenerator

class TestEnglishIPAGeneration:

    def setup_method(self):
        self.generator = EnglishFuzzyGenerator()

    def test_ipa_fuzzy_variants(self):
        """æ¸¬è©¦ IPA éŸ³ç´ æ¨¡ç³Šç”Ÿæˆ"""
        ipa = "ËˆpaÉªÎ¸É‘n"
        variants = self.generator._generate_ipa_fuzzy_variants(ipa)

        # æ‡‰åŒ…å«æ¸…æ¿éŸ³è®Šé«”
        assert any('b' in v or 'p' in v for v in variants)
        # æ‡‰åŒ…å«ç›¸ä¼¼éŸ³è®Šé«”
        assert any('f' in v or 'Î¸' in v for v in variants)
        # è®Šé«”æ•¸é‡åˆç†
        assert 5 <= len(variants) <= 30

    def test_new_word_generalization(self):
        """æ¸¬è©¦æ–°è©æ³›åŒ–èƒ½åŠ›ï¼ˆé—œéµæ¸¬è©¦ï¼‰"""
        # é€™äº›è©åœ¨ç¡¬ç·¨ç¢¼å­—å…¸ä¸­ä¸å­˜åœ¨
        new_words = ["Ollama", "LangChain", "Huggingface"]

        for word in new_words:
            variants = self.generator.generate_variants(word)

            # æ‡‰è©²èƒ½ç”Ÿæˆè®Šé«”ï¼ˆä¸æ‡‰è©²æ˜¯ç©ºåˆ—è¡¨ï¼‰
            assert len(variants) > 0, f"Failed to generate variants for '{word}'"

            # è®Šé«”æ‡‰è©²èˆ‡åŸè©éŸ³ç´ ç›¸ä¼¼
            # ï¼ˆé€™è£¡éœ€è¦å¯¦éš›æª¢æŸ¥ IPA è·é›¢ï¼‰

    def test_deduplication_by_ipa(self):
        """æ¸¬è©¦åŸºæ–¼ IPA çš„å»é‡"""
        # "read" (ç¾åœ¨æ™‚) å’Œ "reed" ç™¼éŸ³ç›¸åŒ
        variants_read = self.generator.generate_variants("read")

        # ä¸æ‡‰è©²åŒæ™‚åŒ…å« "reed" å’Œå…¶ä»– IPA ç›¸åŒçš„è®Šé«”
        # ï¼ˆéœ€è¦æª¢æŸ¥ IPA phonetic keyï¼‰

    def test_ipa_distance_filtering(self):
        """æ¸¬è©¦ IPA è·é›¢éæ¿¾"""
        variants = self.generator.generate_variants("Python")

        # æ‰€æœ‰è®Šé«”çš„ IPA èˆ‡åŸè©çš„è·é›¢æ‡‰åœ¨é–¾å€¼å…§
        base_ipa = self.generator.phonetic.to_phonetic("Python")

        for variant in variants:
            variant_ipa = self.generator.phonetic.to_phonetic(variant)
            dist = Levenshtein.distance(base_ipa, variant_ipa)

            threshold = max(2, int(len(base_ipa) * 0.35))
            assert dist <= threshold, f"'{variant}' IPA distance too large: {dist}"

    def test_hybrid_approach(self):
        """æ¸¬è©¦æ··åˆæ–¹æ³•ï¼ˆIPA + ç¡¬ç·¨ç¢¼è¦å‰‡ï¼‰"""
        variants = self.generator.generate_variants("TensorFlow")

        # æ‡‰åŒ…å« IPA ç”Ÿæˆçš„è®Šé«”
        # ä¹Ÿæ‡‰åŒ…å«ç¡¬ç·¨ç¢¼è¦å‰‡çš„è®Šé«”ï¼ˆå¦‚ "ten so floor"ï¼‰
        assert "ten so floor" in [v.lower() for v in variants]
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] æ‰€æœ‰æ¸¬è©¦é€šé
- [ ] æ–°è©æ³›åŒ–æ¸¬è©¦è­‰æ˜ IPA æ–¹æ³•æœ‰æ•ˆ
- [ ] IPA å»é‡æ¸¬è©¦é©—è­‰æ­£ç¢ºæ€§
- [ ] æ€§èƒ½æ¸¬è©¦ï¼šç”Ÿæˆ 30 å€‹è®Šé«” < 500ms

---

#### Task 5.6: æ–‡æª”æ›´æ–°ï¼ˆ1å¤©ï¼‰

**æ–‡ä»¶**ï¼š
- `src/phonofix/languages/english/fuzzy_generator.py`ï¼ˆdocstringï¼‰
- `README.md`
- `references/API_Documentation.md`

**ä»»å‹™æè¿°**ï¼š
1. æ›´æ–° docstring åæ˜  IPA å¯¦ç¾
2. æ›´æ–° README ç¯„ä¾‹
3. æ·»åŠ  IPA é…ç½®èªªæ˜

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] æ‰€æœ‰ docstring æº–ç¢ºåæ˜ å¯¦ç¾
- [ ] README åŒ…å« IPA è®Šé«”ç”Ÿæˆç¯„ä¾‹
- [ ] API æ–‡æª”æ›´æ–°å®Œæ•´

---

### ğŸ¯ Phase 2 é©—æ”¶æ¨™æº–ç¸½è¡¨

| ä»»å‹™ | é©—æ”¶æ¨™æº– | å„ªå…ˆç´š |
|------|---------|--------|
| 5.1 IPA éŸ³ç´ è¦å‰‡ | â‰¥20 æ¢è¦å‰‡ï¼Œæ¶µè“‹ 4 ç¨®é¡å‹ | P0 |
| 5.2 IPA è®Šé«”ç”Ÿæˆ | é€šéå–®å…ƒæ¸¬è©¦ | P0 |
| 5.3 IPAâ†’æ‹¼å¯«åæŸ¥ | æ•´åˆ CMU Dictï¼Œé€šé 20+ æ¸¬è©¦ | P0 |
| 5.4 ä¸»æµç¨‹é‡æ§‹ | é€šéæ‰€æœ‰æ¸¬è©¦ï¼ŒIPA å»é‡æ­£ç¢º | P0 |
| 5.5 æ¸¬è©¦èˆ‡é©—è­‰ | æ–°è©æ³›åŒ–æ¸¬è©¦é€šé | P0 |
| 5.6 æ–‡æª”æ›´æ–° | æ–‡æª”æº–ç¢ºå®Œæ•´ | P1 |

**Phase 2 ç¸½å·¥æ™‚**ï¼š1-2é€±ï¼ˆ10-14 å·¥ä½œæ—¥ï¼‰

---

## ğŸ—ï¸ Phase 3: çµ±ä¸€æ¶æ§‹ BaseFuzzyGeneratorï¼ˆ1é€±ï¼‰

### ğŸ“Œ æ ¸å¿ƒç›®æ¨™

**å»ºç«‹çµ±ä¸€æŠ½è±¡åŸºé¡ï¼Œå¼·åˆ¶ä¸‰èªè¨€æ¶æ§‹ä¸€è‡´**

**ç•¶å‰å•é¡Œ**ï¼š
- âŒ æ¥å£ä¸ä¸€è‡´ï¼ˆä¸­æ–‡/æ—¥æ–‡/è‹±æ–‡å„è‡ªç‚ºæ”¿ï¼‰
- âŒ é‡è¤‡ä»£ç¢¼ï¼ˆæ¯å€‹èªè¨€éƒ½å¯¦ç¾ç›¸ä¼¼é‚è¼¯ï¼‰
- âŒ é›£ä»¥æ·»åŠ æ–°èªè¨€ï¼ˆéŸ“æ–‡ã€æ³°æ–‡ç­‰ï¼‰
- âŒ ç¼ºå°‘çµ±ä¸€çš„è®Šé«”è©•åˆ†æ©Ÿåˆ¶

**ç›®æ¨™æ¶æ§‹**ï¼š
```
BaseFuzzyGenerator (æŠ½è±¡åŸºé¡)
â”œâ”€â”€ ChineseFuzzyGenerator (Pinyin å¯¦ç¾)
â”œâ”€â”€ EnglishFuzzyGenerator (IPA å¯¦ç¾)
â”œâ”€â”€ JapaneseFuzzyGenerator (Romaji å¯¦ç¾)
â””â”€â”€ KoreanFuzzyGenerator (Hangul å¯¦ç¾, æœªä¾†)
```

---

### ğŸ“… è©³ç´°ä»»å‹™åˆ†è§£

#### Task 6.1: è¨­è¨ˆæŠ½è±¡åŸºé¡ï¼ˆ2å¤©ï¼‰

**æ–‡ä»¶**ï¼š`src/phonofix/core/fuzzy_generator_interface.py`ï¼ˆæ–°å»ºï¼‰

**ä»»å‹™æè¿°**ï¼š
1. å®šç¾©çµ±ä¸€çš„è®Šé«”æ•¸æ“šçµæ§‹
2. è¨­è¨ˆæŠ½è±¡æ–¹æ³•æ¥å£
3. å¯¦ç¾æ¨¡æ¿æ–¹æ³•

**æ–°å¢æ¨¡çµ„**ï¼š
```python
# src/phonofix/core/fuzzy_generator_interface.py

from abc import ABC, abstractmethod
from typing import List, Dict, Any
from dataclasses import dataclass
from enum import Enum

class VariantSource(Enum):
    """è®Šé«”ä¾†æºé¡å‹"""
    PHONETIC_FUZZY = "phonetic_fuzzy"    # èªéŸ³æ¨¡ç³Šè¦å‰‡
    HARDCODED_PATTERN = "hardcoded"      # ç¡¬ç·¨ç¢¼æ¨¡å¼
    PHRASE_RULE = "phrase_rule"          # æ•´è©è¦å‰‡
    ROMANIZATION = "romanization"        # ç¾…é¦¬åŒ–è®Šé«”

@dataclass
class PhoneticVariant:
    """
    èªéŸ³è®Šé«”çµæ§‹ï¼ˆçµ±ä¸€æ ¼å¼ï¼‰

    Attributes:
        text: é¡¯ç¤ºæ–‡å­—ï¼ˆä½¿ç”¨è€…çœ‹åˆ°çš„ï¼‰
        phonetic_key: èªéŸ³keyï¼ˆPinyin/IPA/Romajiï¼Œç”¨æ–¼å»é‡ï¼‰
        score: ç½®ä¿¡åº¦è©•åˆ† (0.0-1.0)
        source: è®Šé«”ä¾†æºé¡å‹
        metadata: é¡å¤–å…ƒæ•¸æ“šï¼ˆå¦‚éŸ³ç´ è¦å‰‡é¡å‹ï¼‰
    """
    text: str
    phonetic_key: str
    score: float = 1.0
    source: VariantSource = VariantSource.PHONETIC_FUZZY
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class BaseFuzzyGenerator(ABC):
    """
    æ¨¡ç³Šè®Šé«”ç”Ÿæˆå™¨æŠ½è±¡åŸºé¡

    çµ±ä¸€æµç¨‹ï¼ˆæ¨¡æ¿æ–¹æ³•ï¼‰ï¼š
    1. æ–‡å­— â†’ èªéŸ³key (phonetic_transform)
    2. èªéŸ³key â†’ æ¨¡ç³ŠèªéŸ³keyè®Šé«” (generate_phonetic_variants)
    3. æ¨¡ç³ŠèªéŸ³key â†’ æ–‡å­— (phonetic_to_text)
    4. åŸºæ–¼èªéŸ³keyå»é‡ (deduplicate_by_phonetic)
    5. è©•åˆ†èˆ‡æ’åº (score_and_rank)
    """

    def __init__(self, config=None):
        self.config = config

    # ========== æŠ½è±¡æ–¹æ³•ï¼ˆå­é¡å¿…é ˆå¯¦ç¾ï¼‰==========

    @abstractmethod
    def phonetic_transform(self, term: str) -> str:
        """
        æ–‡å­— â†’ èªéŸ³key

        Args:
            term: è¼¸å…¥æ–‡å­—ï¼ˆå¦‚ "å°åŒ—", "Python", "æ±äº¬"ï¼‰

        Returns:
            str: èªéŸ³keyï¼ˆå¦‚ "taibei", "ËˆpaÉªÎ¸É‘n", "toukyou"ï¼‰
        """
        pass

    @abstractmethod
    def generate_phonetic_variants(self, phonetic_key: str) -> List[str]:
        """
        èªéŸ³key â†’ æ¨¡ç³ŠèªéŸ³keyè®Šé«”

        Args:
            phonetic_key: æ¨™æº–èªéŸ³key

        Returns:
            List[str]: æ¨¡ç³ŠèªéŸ³keyåˆ—è¡¨
        """
        pass

    @abstractmethod
    def phonetic_to_text(self, phonetic_key: str) -> str:
        """
        èªéŸ³key â†’ ä»£è¡¨æ–‡å­—ï¼ˆç”¨æ–¼ UX å±•ç¤ºï¼‰

        Args:
            phonetic_key: èªéŸ³key

        Returns:
            str: ä»£è¡¨æ€§æ–‡å­—
        """
        pass

    # ========== å¯é¸æ–¹æ³•ï¼ˆå­é¡å¯è¦†è“‹ï¼‰==========

    def apply_hardcoded_rules(self, term: str) -> List[str]:
        """
        æ‡‰ç”¨ç¡¬ç·¨ç¢¼è¦å‰‡ï¼ˆè£œå……ï¼‰

        Args:
            term: è¼¸å…¥æ–‡å­—

        Returns:
            List[str]: ç¡¬ç·¨ç¢¼è¦å‰‡ç”Ÿæˆçš„è®Šé«”
        """
        return []

    def calculate_score(self, base_key: str, variant_key: str) -> float:
        """
        è¨ˆç®—è®Šé«”ç½®ä¿¡åº¦è©•åˆ†

        Args:
            base_key: åŸå§‹èªéŸ³key
            variant_key: è®Šé«”èªéŸ³key

        Returns:
            float: è©•åˆ† (0.0-1.0)
        """
        import Levenshtein

        # åŸºæ–¼ç·¨è¼¯è·é›¢è¨ˆç®—è©•åˆ†
        dist = Levenshtein.distance(base_key, variant_key)
        max_len = max(len(base_key), len(variant_key))

        if max_len == 0:
            return 1.0

        similarity = 1.0 - (dist / max_len)
        return max(0.0, similarity)

    # ========== æ¨¡æ¿æ–¹æ³•ï¼ˆçµ±ä¸€æµç¨‹ï¼‰==========

    def generate_variants(
        self,
        term: str,
        max_variants: int = 30,
        include_hardcoded: bool = True
    ) -> List[PhoneticVariant]:
        """
        çµ±ä¸€çš„è®Šé«”ç”Ÿæˆæµç¨‹ï¼ˆæ¨¡æ¿æ–¹æ³•ï¼‰

        Args:
            term: è¼¸å…¥è©å½™
            max_variants: æœ€å¤§è®Šé«”æ•¸é‡
            include_hardcoded: æ˜¯å¦åŒ…å«ç¡¬ç·¨ç¢¼è¦å‰‡

        Returns:
            List[PhoneticVariant]: è®Šé«”åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
        """
        variants = []

        # ========== Step 1: èªéŸ³ç¶­åº¦ç”Ÿæˆ ==========
        try:
            # 1.1 æ–‡å­— â†’ èªéŸ³key
            base_phonetic = self.phonetic_transform(term)

            # 1.2 èªéŸ³key â†’ æ¨¡ç³ŠèªéŸ³keyè®Šé«”
            phonetic_variants = self.generate_phonetic_variants(base_phonetic)

            # 1.3 æ¨¡ç³ŠèªéŸ³key â†’ æ–‡å­—
            for p_var in phonetic_variants:
                text = self.phonetic_to_text(p_var)
                score = self.calculate_score(base_phonetic, p_var)

                variants.append(PhoneticVariant(
                    text=text,
                    phonetic_key=p_var,
                    score=score,
                    source=VariantSource.PHONETIC_FUZZY
                ))

        except Exception as e:
            # èªéŸ³ç”Ÿæˆå¤±æ•—ï¼Œè¨˜éŒ„éŒ¯èª¤ä½†ç¹¼çºŒ
            import logging
            logging.warning(f"Phonetic generation failed for '{term}': {e}")

        # ========== Step 2: ç¡¬ç·¨ç¢¼è¦å‰‡ï¼ˆè£œå……ï¼‰==========
        if include_hardcoded:
            hardcoded_texts = self.apply_hardcoded_rules(term)

            for text in hardcoded_texts:
                try:
                    p_key = self.phonetic_transform(text)
                    variants.append(PhoneticVariant(
                        text=text,
                        phonetic_key=p_key,
                        score=0.8,  # ç¡¬ç·¨ç¢¼è¦å‰‡è©•åˆ†ç¨ä½
                        source=VariantSource.HARDCODED_PATTERN
                    ))
                except:
                    # ç„¡æ³•ç²å–èªéŸ³keyï¼Œä½¿ç”¨æ–‡å­—æœ¬èº«
                    variants.append(PhoneticVariant(
                        text=text,
                        phonetic_key=text,
                        score=0.7,
                        source=VariantSource.HARDCODED_PATTERN
                    ))

        # ========== Step 3: åŸºæ–¼èªéŸ³keyå»é‡ ==========
        unique_variants = self._deduplicate_by_phonetic(variants)

        # ========== Step 4: éæ¿¾åŸè© ==========
        filtered = [
            v for v in unique_variants
            if v.text.lower() != term.lower()
        ]

        # ========== Step 5: è©•åˆ†èˆ‡æ’åº ==========
        sorted_variants = sorted(
            filtered,
            key=lambda v: (-v.score, len(v.text), v.text)
        )

        return sorted_variants[:max_variants]

    def _deduplicate_by_phonetic(self, variants: List[PhoneticVariant]) -> List[PhoneticVariant]:
        """åŸºæ–¼èªéŸ³keyå»é‡ï¼ˆä¿ç•™è©•åˆ†æœ€é«˜çš„ï¼‰"""
        seen_keys = {}

        for variant in variants:
            key = variant.phonetic_key

            if key not in seen_keys:
                seen_keys[key] = variant
            else:
                # ä¿ç•™è©•åˆ†æ›´é«˜çš„
                if variant.score > seen_keys[key].score:
                    seen_keys[key] = variant

        return list(seen_keys.values())

    def filter_homophones(self, term_list: List[str]) -> Dict[str, List[str]]:
        """
        éæ¿¾åŒéŸ³è©ï¼ˆåŸºæ–¼èªéŸ³keyï¼‰

        Args:
            term_list: è©å½™åˆ—è¡¨

        Returns:
            Dict: {"kept": [...], "filtered": [...]}
        """
        kept = []
        filtered = []
        seen_keys = set()

        for term in term_list:
            try:
                key = self.phonetic_transform(term)
            except:
                key = term  # ç„¡æ³•ç²å–èªéŸ³keyï¼Œä½¿ç”¨æ–‡å­—

            if key in seen_keys:
                filtered.append(term)
            else:
                kept.append(term)
                seen_keys.add(key)

        return {"kept": kept, "filtered": filtered}
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] æŠ½è±¡åŸºé¡å®šç¾©æ¸…æ™°
- [ ] PhoneticVariant æ•¸æ“šçµæ§‹å®Œæ•´
- [ ] æ¨¡æ¿æ–¹æ³•å¯¦ç¾çµ±ä¸€æµç¨‹
- [ ] æ–‡æª”è¨»é‡‹è©³ç›¡

---

#### Task 6.2: é‡æ§‹ä¸­æ–‡æ¨¡çµ„ï¼ˆ1å¤©ï¼‰

**æ–‡ä»¶**ï¼š`src/phonofix/languages/chinese/fuzzy_generator.py`

**ä»»å‹™æè¿°**ï¼š
1. ç¹¼æ‰¿ BaseFuzzyGenerator
2. å¯¦ç¾æŠ½è±¡æ–¹æ³•
3. ä¿ç•™ç¾æœ‰åŠŸèƒ½

**é‡æ§‹å¾Œçš„é¡**ï¼š
```python
# src/phonofix/languages/chinese/fuzzy_generator.py

from phonofix.core.fuzzy_generator_interface import (
    BaseFuzzyGenerator,
    PhoneticVariant,
    VariantSource
)
from .config import ChinesePhoneticConfig
from .utils import ChinesePhoneticUtils

class ChineseFuzzyGenerator(BaseFuzzyGenerator):
    """ä¸­æ–‡æ¨¡ç³Šè®Šé«”ç”Ÿæˆå™¨ï¼ˆåŸºæ–¼ Pinyinï¼‰"""

    def __init__(self, config=None):
        super().__init__(config)
        self.config = config or ChinesePhoneticConfig
        self.utils = ChinesePhoneticUtils(config=self.config)
        self._dag_params = None
        self._logger = get_logger("fuzzy.chinese")

    # ========== å¯¦ç¾æŠ½è±¡æ–¹æ³• ==========

    def phonetic_transform(self, term: str) -> str:
        """æ–‡å­— â†’ Pinyin"""
        return self.utils.get_pinyin_string(term)

    def generate_phonetic_variants(self, phonetic_key: str) -> List[str]:
        """Pinyin â†’ æ¨¡ç³Š Pinyin è®Šé«”"""
        return self.utils.generate_fuzzy_pinyin_variants(
            phonetic_key,
            bidirectional=True
        )

    def phonetic_to_text(self, phonetic_key: str) -> str:
        """Pinyin â†’ æ¼¢å­—ï¼ˆä½¿ç”¨åæŸ¥ï¼‰"""
        # ä½¿ç”¨ç¾æœ‰çš„ _pinyin_to_chars æ–¹æ³•
        chars = self._pinyin_to_chars(phonetic_key, max_chars=1)
        return chars[0] if chars else phonetic_key

    def apply_hardcoded_rules(self, term: str) -> List[str]:
        """æ‡‰ç”¨é»éŸ³/æ‡¶éŸ³è¦å‰‡"""
        hardcoded = []

        if term in self.config.STICKY_PHRASE_MAP:
            hardcoded.extend(self.config.STICKY_PHRASE_MAP[term])

        return hardcoded

    # ========== ä¿ç•™ç¾æœ‰æ–¹æ³• ==========
    # _get_char_variations()
    # _generate_char_combinations()
    # _add_sticky_phrase_aliases()
    # ç­‰æ–¹æ³•ä¿æŒä¸è®Š
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] ç¹¼æ‰¿ BaseFuzzyGenerator
- [ ] å¯¦ç¾æ‰€æœ‰æŠ½è±¡æ–¹æ³•
- [ ] é€šéæ‰€æœ‰ç¾æœ‰æ¸¬è©¦
- [ ] ä¿æŒå‘å¾Œå…¼å®¹

---

#### Task 6.3: é‡æ§‹è‹±æ–‡æ¨¡çµ„ï¼ˆ1å¤©ï¼‰

**æ–‡ä»¶**ï¼š`src/phonofix/languages/english/fuzzy_generator.py`

**ä»»å‹™æè¿°**ï¼š
1. ç¹¼æ‰¿ BaseFuzzyGenerator
2. å¯¦ç¾æŠ½è±¡æ–¹æ³•
3. æ•´åˆ Phase 2 çš„ IPA å¯¦ç¾

**é‡æ§‹å¾Œçš„é¡**ï¼š
```python
# src/phonofix/languages/english/fuzzy_generator.py

from phonofix.core.fuzzy_generator_interface import (
    BaseFuzzyGenerator,
    PhoneticVariant,
    VariantSource
)
from .config import EnglishPhoneticConfig
from .ipa_to_spelling import IPAToSpellingMapper
from phonofix.core.phonetic_interface import PhoneticSystem

class EnglishFuzzyGenerator(BaseFuzzyGenerator):
    """è‹±æ–‡æ¨¡ç³Šè®Šé«”ç”Ÿæˆå™¨ï¼ˆåŸºæ–¼ IPAï¼‰"""

    def __init__(self, config=None):
        super().__init__(config)
        self.config = config or EnglishPhoneticConfig()
        self.phonetic = EnglishPhoneticSystem()
        self.ipa_mapper = IPAToSpellingMapper()

    # ========== å¯¦ç¾æŠ½è±¡æ–¹æ³• ==========

    def phonetic_transform(self, term: str) -> str:
        """æ–‡å­— â†’ IPA"""
        return self.phonetic.to_phonetic(term)

    def generate_phonetic_variants(self, phonetic_key: str) -> List[str]:
        """IPA â†’ æ¨¡ç³Š IPA è®Šé«”"""
        return self._generate_ipa_fuzzy_variants(phonetic_key)

    def phonetic_to_text(self, phonetic_key: str) -> str:
        """IPA â†’ æ‹¼å¯«"""
        spellings = self.ipa_mapper.ipa_to_spellings(phonetic_key, max_results=1)
        return spellings[0] if spellings else phonetic_key

    def apply_hardcoded_rules(self, term: str) -> List[str]:
        """æ‡‰ç”¨ ASR åˆ†è©æ¨¡å¼å’Œæ‹¼å¯«è¦å‰‡"""
        hardcoded = []

        # ä¿ç•™ç¾æœ‰æ–¹æ³•
        hardcoded.extend(self._generate_full_word_variants(term))
        hardcoded.extend(self._generate_acronym_variants(term))
        hardcoded.extend(self._generate_compound_variants(term))
        hardcoded.extend(self._apply_spelling_patterns(term))

        return hardcoded

    # ========== ä¿ç•™ç¾æœ‰æ–¹æ³•ï¼ˆPhase 2 å¯¦ç¾ï¼‰==========
    # _generate_ipa_fuzzy_variants()
    # _generate_full_word_variants()
    # ...
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] ç¹¼æ‰¿ BaseFuzzyGenerator
- [ ] å¯¦ç¾æ‰€æœ‰æŠ½è±¡æ–¹æ³•
- [ ] æ•´åˆ IPA å¯¦ç¾
- [ ] é€šéæ‰€æœ‰æ¸¬è©¦

---

#### Task 6.4: é‡æ§‹æ—¥æ–‡æ¨¡çµ„ï¼ˆ1å¤©ï¼‰

**æ–‡ä»¶**ï¼š`src/phonofix/languages/japanese/fuzzy_generator.py`

**ä»»å‹™æè¿°**ï¼š
1. ç¹¼æ‰¿ BaseFuzzyGenerator
2. å¯¦ç¾æŠ½è±¡æ–¹æ³•
3. ä¿ç•™å‡å/ç¾…é¦¬å­—é›™é‡é‚è¼¯

**é‡æ§‹å¾Œçš„é¡**ï¼š
```python
# src/phonofix/languages/japanese/fuzzy_generator.py

from phonofix.core.fuzzy_generator_interface import (
    BaseFuzzyGenerator,
    PhoneticVariant,
    VariantSource
)
from .config import JapanesePhoneticConfig
from .utils import _get_fugashi, _get_cutlet

class JapaneseFuzzyGenerator(BaseFuzzyGenerator):
    """æ—¥æ–‡æ¨¡ç³Šè®Šé«”ç”Ÿæˆå™¨ï¼ˆåŸºæ–¼ Romajiï¼‰"""

    def __init__(self, config=None):
        super().__init__(config)
        self.config = config or JapanesePhoneticConfig()

    # ========== å¯¦ç¾æŠ½è±¡æ–¹æ³• ==========

    def phonetic_transform(self, term: str) -> str:
        """æ–‡å­— â†’ Romajiï¼ˆä½¿ç”¨ Phase 1 çš„æ­£è¦åŒ–é‚è¼¯ï¼‰"""
        return self._get_phonetic_key(term)  # ä¿ç•™ Phase 1 å¯¦ç¾

    def generate_phonetic_variants(self, phonetic_key: str) -> List[str]:
        """Romaji â†’ æ¨¡ç³Š Romaji è®Šé«”"""
        return list(self._apply_romaji_config_rules(phonetic_key))

    def phonetic_to_text(self, phonetic_key: str) -> str:
        """Romaji â†’ å‡å/æ¼¢å­—"""
        # ç°¡åŒ–å¯¦ç¾ï¼šç›´æ¥è¿”å› phonetic_key
        # æœªä¾†å¯æ“´å±•ï¼šåæŸ¥å‡åæˆ–æ¼¢å­—
        return phonetic_key

    def apply_hardcoded_rules(self, term: str) -> List[str]:
        """æ‡‰ç”¨å‡åå±¤ç´šè¦å‰‡"""
        hardcoded = []

        # å‡åè®Šé«”ç”Ÿæˆï¼ˆä¿ç•™ç¾æœ‰é‚è¼¯ï¼‰
        hira_parts = self._kanji_to_hiragana_list(term)
        base_hira = "".join(hira_parts)

        # æ‡‰ç”¨å‡åè¦å‰‡
        kana_variants = self._apply_kana_phrase_rules(base_hira)
        hardcoded.extend(kana_variants)

        return hardcoded

    # ========== ä¿ç•™ç¾æœ‰æ–¹æ³• ==========
    # _kata_to_hira()
    # _kanji_to_hiragana_list()
    # _get_kana_variations()
    # _apply_kana_phrase_rules()
    # _get_phonetic_key() (Phase 1 å¯¦ç¾)
    # ...
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] ç¹¼æ‰¿ BaseFuzzyGenerator
- [ ] å¯¦ç¾æ‰€æœ‰æŠ½è±¡æ–¹æ³•
- [ ] ä¿æŒå‡å/ç¾…é¦¬å­—é›™é‡ç”Ÿæˆ
- [ ] é€šéæ‰€æœ‰æ¸¬è©¦

---

#### Task 6.5: æ¸¬è©¦èˆ‡é©—è­‰ï¼ˆ1å¤©ï¼‰

**æ–‡ä»¶**ï¼š`tests/test_base_fuzzy_generator.py`ï¼ˆæ–°å»ºï¼‰

**ä»»å‹™æè¿°**ï¼š
1. æ¸¬è©¦çµ±ä¸€æ¥å£
2. é©—è­‰ä¸‰èªè¨€ä¸€è‡´æ€§
3. æ€§èƒ½æ¸¬è©¦

**æ¸¬è©¦æ¡ˆä¾‹**ï¼š
```python
# tests/test_base_fuzzy_generator.py

import pytest
from phonofix.languages.chinese.fuzzy_generator import ChineseFuzzyGenerator
from phonofix.languages.english.fuzzy_generator import EnglishFuzzyGenerator
from phonofix.languages.japanese.fuzzy_generator import JapaneseFuzzyGenerator
from phonofix.core.fuzzy_generator_interface import PhoneticVariant

class TestUnifiedInterface:
    """æ¸¬è©¦çµ±ä¸€æ¥å£"""

    def test_all_generators_have_same_interface(self):
        """æ‰€æœ‰ç”Ÿæˆå™¨æ‡‰æœ‰ç›¸åŒçš„æ¥å£"""
        generators = [
            ChineseFuzzyGenerator(),
            EnglishFuzzyGenerator(),
            JapaneseFuzzyGenerator()
        ]

        for gen in generators:
            # æ‡‰æœ‰ generate_variants æ–¹æ³•
            assert hasattr(gen, 'generate_variants')

            # æ‡‰æœ‰æŠ½è±¡æ–¹æ³•
            assert hasattr(gen, 'phonetic_transform')
            assert hasattr(gen, 'generate_phonetic_variants')
            assert hasattr(gen, 'phonetic_to_text')

    def test_return_type_consistency(self):
        """è¿”å›é¡å‹æ‡‰ä¸€è‡´"""
        test_cases = [
            (ChineseFuzzyGenerator(), "å°åŒ—"),
            (EnglishFuzzyGenerator(), "Python"),
            (JapaneseFuzzyGenerator(), "æ±äº¬")
        ]

        for gen, term in test_cases:
            variants = gen.generate_variants(term)

            # æ‡‰è¿”å› List[PhoneticVariant]
            assert isinstance(variants, list)

            for variant in variants:
                assert isinstance(variant, PhoneticVariant)
                assert hasattr(variant, 'text')
                assert hasattr(variant, 'phonetic_key')
                assert hasattr(variant, 'score')

    def test_phonetic_deduplication(self):
        """åŸºæ–¼èªéŸ³keyçš„å»é‡æ‡‰æ­£ç¢º"""
        # ä¸­æ–‡åŒéŸ³è©
        gen_zh = ChineseFuzzyGenerator()
        homophones_zh = ["å°åŒ—", "è‹”èƒŒ"]  # åŒéŸ³
        result_zh = gen_zh.filter_homophones(homophones_zh)

        assert len(result_zh["kept"]) == 1
        assert len(result_zh["filtered"]) == 1

    def test_scoring_consistency(self):
        """è©•åˆ†æ‡‰åœ¨ 0.0-1.0 ç¯„åœå…§"""
        generators = [
            (ChineseFuzzyGenerator(), "æ¸¬è©¦"),
            (EnglishFuzzyGenerator(), "test"),
            (JapaneseFuzzyGenerator(), "ãƒ†ã‚¹ãƒˆ")
        ]

        for gen, term in generators:
            variants = gen.generate_variants(term)

            for variant in variants:
                assert 0.0 <= variant.score <= 1.0
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] çµ±ä¸€æ¥å£æ¸¬è©¦é€šé
- [ ] ä¸‰èªè¨€ä¸€è‡´æ€§é©—è­‰é€šé
- [ ] æ€§èƒ½æ¸¬è©¦ç„¡å›æ­¸
- [ ] æ‰€æœ‰ç¾æœ‰æ¸¬è©¦ä»ç„¶é€šé

---

### ğŸ¯ Phase 3 é©—æ”¶æ¨™æº–ç¸½è¡¨

| ä»»å‹™ | é©—æ”¶æ¨™æº– | å„ªå…ˆç´š |
|------|---------|--------|
| 6.1 æŠ½è±¡åŸºé¡è¨­è¨ˆ | æ¥å£æ¸…æ™°ï¼Œæ–‡æª”å®Œæ•´ | P0 |
| 6.2 é‡æ§‹ä¸­æ–‡æ¨¡çµ„ | å‘å¾Œå…¼å®¹ï¼Œé€šéæ¸¬è©¦ | P0 |
| 6.3 é‡æ§‹è‹±æ–‡æ¨¡çµ„ | æ•´åˆ IPAï¼Œé€šéæ¸¬è©¦ | P0 |
| 6.4 é‡æ§‹æ—¥æ–‡æ¨¡çµ„ | ä¿ç•™é›™é‡é‚è¼¯ï¼Œé€šéæ¸¬è©¦ | P0 |
| 6.5 æ¸¬è©¦èˆ‡é©—è­‰ | çµ±ä¸€æ¥å£æ¸¬è©¦é€šé | P0 |

**Phase 3 ç¸½å·¥æ™‚**ï¼š1é€±ï¼ˆ5 å·¥ä½œæ—¥ï¼‰

---

## ğŸŒŸ Phase 4: æŒçºŒå„ªåŒ–èˆ‡åŠŸèƒ½å¢å¼·ï¼ˆ2-3å¤©ï¼‰

### ğŸ“Œ æ ¸å¿ƒç›®æ¨™

**æ·»åŠ æ—¥æ–‡æ¼¢å­—è®Šé«”ç”Ÿæˆ + å…¶ä»–å„ªåŒ–**

---

### ğŸ“… è©³ç´°ä»»å‹™åˆ†è§£

#### Task 7.1: æ—¥æ–‡æ¼¢å­—è®Šé«”ç”Ÿæˆï¼ˆ2å¤©ï¼‰â­

**æ–‡ä»¶**ï¼š`src/phonofix/languages/japanese/fuzzy_generator.py`

**ä»»å‹™æè¿°**ï¼š
1. å¯¦ç¾å‡å â†’ æ¼¢å­—åæŸ¥
2. ä¿ç•™åŸè©çš„æ¼¢å­—å½¢å¼
3. ç”ŸæˆåŒéŸ³ç•°å­—è®Šé«”

**å¯¦ç¾æ–¹æ¡ˆ**ï¼š
```python
class JapaneseFuzzyGenerator(BaseFuzzyGenerator):

    def generate_variants(self, term: str, max_variants: int = 30) -> List[PhoneticVariant]:
        """
        ç”Ÿæˆæ—¥æ–‡è®Šé«”ï¼ˆåŒ…å«æ¼¢å­—ï¼‰

        é‡å¯«çˆ¶é¡æ–¹æ³•ä»¥æ”¯æŒæ¼¢å­—è®Šé«”
        """
        variants = []

        # ========== 1. èªéŸ³ç¶­åº¦ç”Ÿæˆ ==========
        # èª¿ç”¨çˆ¶é¡æ–¹æ³•ç²å–å‡å/ç¾…é¦¬å­—è®Šé«”
        phonetic_variants = super().generate_variants(
            term,
            max_variants=max_variants * 2,  # å¤šç”Ÿæˆä¸€äº›ï¼Œå¾ŒçºŒéæ¿¾
            include_hardcoded=True
        )
        variants.extend(phonetic_variants)

        # ========== 2. æ¼¢å­—è®Šé«”ç”Ÿæˆï¼ˆæ–°å¢ï¼‰==========
        if self._has_kanji(term):
            kanji_variants = self._generate_kanji_variants(term)
            variants.extend(kanji_variants)

        # ========== 3. å»é‡èˆ‡æ’åº ==========
        unique = self._deduplicate_by_phonetic(variants)
        sorted_variants = sorted(
            unique,
            key=lambda v: (-v.score, len(v.text), v.text)
        )

        return sorted_variants[:max_variants]

    def _has_kanji(self, text: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦åŒ…å«æ¼¢å­—"""
        return any('\u4e00' <= ch <= '\u9fff' for ch in text)

    def _generate_kanji_variants(self, term: str) -> List[PhoneticVariant]:
        """
        ç”Ÿæˆæ¼¢å­—è®Šé«”

        ç­–ç•¥ï¼š
        1. ä¿ç•™åŸè©çš„æ¼¢å­—å½¢å¼
        2. ä½¿ç”¨ fugashi/mecab çš„å­—å…¸ç²å–åŒéŸ³ç•°å­—
        """
        variants = []

        # 1. ä¿ç•™åŸè©æ¼¢å­—
        base_phonetic = self.phonetic_transform(term)
        variants.append(PhoneticVariant(
            text=term,
            phonetic_key=base_phonetic,
            score=1.0,
            source=VariantSource.PHONETIC_FUZZY,
            metadata={"type": "original_kanji"}
        ))

        # 2. ç”ŸæˆåŒéŸ³ç•°å­—ï¼ˆä½¿ç”¨ mecab å­—å…¸ï¼‰
        kanji_candidates = self._lookup_homophones_from_dict(term)

        for candidate in kanji_candidates:
            candidate_phonetic = self.phonetic_transform(candidate)
            score = self.calculate_score(base_phonetic, candidate_phonetic)

            variants.append(PhoneticVariant(
                text=candidate,
                phonetic_key=candidate_phonetic,
                score=score * 0.9,  # åŒéŸ³ç•°å­—è©•åˆ†ç¨ä½
                source=VariantSource.PHONETIC_FUZZY,
                metadata={"type": "kanji_variant"}
            ))

        return variants

    def _lookup_homophones_from_dict(self, term: str) -> List[str]:
        """
        å¾ mecab å­—å…¸ä¸­æŸ¥æ‰¾åŒéŸ³è©

        Args:
            term: åŸå§‹è©ï¼ˆæ¼¢å­—ï¼‰

        Returns:
            List[str]: åŒéŸ³ç•°å­—åˆ—è¡¨
        """
        tagger = _get_fugashi()

        # 1. ç²å–åŸè©çš„è®€éŸ³
        base_reading = None
        for word in tagger(term):
            try:
                base_reading = word.feature.kana
                break
            except AttributeError:
                continue

        if not base_reading:
            return []

        # 2. æŸ¥æ‰¾å…·æœ‰ç›¸åŒè®€éŸ³çš„å…¶ä»–è©
        # TODO: é€™éœ€è¦å»ºç«‹åå‘ç´¢å¼•ï¼ˆreading â†’ kanjiï¼‰
        # æš«æ™‚è¿”å›ç©ºåˆ—è¡¨ï¼Œæœªä¾†å¯æ•´åˆ mecab-ipadic å­—å…¸

        # ç°¡åŒ–å¯¦ç¾ï¼šä½¿ç”¨é å®šç¾©çš„åŒéŸ³ç•°å­—è¡¨
        COMMON_HOMOPHONES = {
            "æ±äº¬": ["å‡äº¬", "æ±ç¶“"],
            "ä¼šç¤¾": ["æœƒç¤¾", "å›ç¤¾"],
            # ... æ›´å¤šå¸¸è¦‹åŒéŸ³è©
        }

        return COMMON_HOMOPHONES.get(term, [])
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] ä¿ç•™åŸè©æ¼¢å­—å½¢å¼
- [ ] èƒ½æŸ¥æ‰¾å¸¸è¦‹åŒéŸ³ç•°å­—ï¼ˆè‡³å°‘ 10 å€‹è©ï¼‰
- [ ] é€šéæ¸¬è©¦æ¡ˆä¾‹
- [ ] è©•åˆ†æ©Ÿåˆ¶åˆç†

---

#### Task 7.2: ç§»é™¤æœªä½¿ç”¨çš„ä»£ç¢¼ï¼ˆåŠå¤©ï¼‰

**ä»»å‹™æè¿°**ï¼š
1. ç§»é™¤ `_romaji_reverse_map`ï¼ˆLine 24-29ï¼‰
2. ç§»é™¤å…¶ä»–æœªä½¿ç”¨çš„æ–¹æ³•
3. ä»£ç¢¼æ¸…ç†

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] ç§»é™¤æ‰€æœ‰æœªä½¿ç”¨ä»£ç¢¼
- [ ] é€šéæ‰€æœ‰æ¸¬è©¦
- [ ] ä»£ç¢¼è¦†è“‹ç‡ >90%

---

#### Task 7.3: æ€§èƒ½å„ªåŒ–ï¼ˆ1å¤©ï¼‰

**ä»»å‹™æè¿°**ï¼š
1. æ·»åŠ  LRU ç·©å­˜
2. ä¸¦è¡Œè™•ç†å„ªåŒ–
3. æ€§èƒ½æ¸¬è©¦

**å„ªåŒ–æ–¹æ¡ˆ**ï¼š
```python
from functools import lru_cache

class BaseFuzzyGenerator:

    @lru_cache(maxsize=1000)
    def phonetic_transform(self, term: str) -> str:
        """æ·»åŠ ç·©å­˜"""
        return self._phonetic_transform_impl(term)

    @abstractmethod
    def _phonetic_transform_impl(self, term: str) -> str:
        """å¯¦éš›å¯¦ç¾ï¼ˆç”±å­é¡å¯¦ç¾ï¼‰"""
        pass
```

**é©—æ”¶æ¨™æº–**ï¼š
- [ ] ç·©å­˜å‘½ä¸­ç‡ >80%
- [ ] æ€§èƒ½æå‡ 30-50%
- [ ] é€šéæ€§èƒ½æ¸¬è©¦

---

### ğŸ¯ Phase 4 é©—æ”¶æ¨™æº–ç¸½è¡¨

| ä»»å‹™ | é©—æ”¶æ¨™æº– | å„ªå…ˆç´š |
|------|---------|--------|
| 7.1 æ—¥æ–‡æ¼¢å­—è®Šé«” | ä¿ç•™æ¼¢å­—ï¼ŒæŸ¥æ‰¾åŒéŸ³è© | P1 |
| 7.2 ä»£ç¢¼æ¸…ç† | ç§»é™¤æœªä½¿ç”¨ä»£ç¢¼ | P2 |
| 7.3 æ€§èƒ½å„ªåŒ– | æ€§èƒ½æå‡ 30-50% | P1 |

**Phase 4 ç¸½å·¥æ™‚**ï¼š2-3å¤©

---

## ğŸ“Š ç¸½é«”æ™‚é–“è¡¨èˆ‡é‡Œç¨‹ç¢‘

| Phase | æ ¸å¿ƒç›®æ¨™ | å·¥æ™‚ | é–‹å§‹æ—¥æœŸ | å®Œæˆæ—¥æœŸ | ç‹€æ…‹ |
|-------|---------|------|---------|---------|------|
| Phase 1 | å¿«é€Ÿä¿®å¾© | 1é€± | 2025-12-08 | 2025-12-08 | âœ… å®Œæˆ |
| Phase 2 | è‹±æ–‡ IPA é‡æ§‹ | 1-2é€± | TBD | TBD | â³ å¾…é–‹å§‹ |
| Phase 3 | çµ±ä¸€æ¶æ§‹ | 1é€± | TBD | TBD | â³ å¾…é–‹å§‹ |
| Phase 4 | æŒçºŒå„ªåŒ– | 2-3å¤© | TBD | TBD | â³ å¾…é–‹å§‹ |
| **ç¸½è¨ˆ** | | **3-4é€±** | | | |

---

## ğŸ¯ é—œéµé¢¨éšªèˆ‡æ‡‰å°

### é¢¨éšª1ï¼šIPA â†’ æ‹¼å¯«åæŸ¥å›°é›£ï¼ˆPhase 2ï¼‰

**é¢¨éšªæè¿°**ï¼šCMU Pronouncing Dictionary å¯èƒ½ç„¡æ³•è¦†è“‹æ‰€æœ‰è©å½™

**æ‡‰å°ç­–ç•¥**ï¼š
- ä¸»è¦ï¼šæ•´åˆ CMU Dictï¼ˆè¦†è“‹ 13 è¬è©ï¼‰
- è£œå……ï¼šéŸ³ç´ â†’å­—æ¯è¦å‰‡æ˜ å°„
- å…œåº•ï¼šä¿ç•™ç¡¬ç·¨ç¢¼ ASR_SPLIT_PATTERNS

**å„ªå…ˆç´š**ï¼šP0

---

### é¢¨éšª2ï¼šæ€§èƒ½å›æ­¸ï¼ˆPhase 3ï¼‰

**é¢¨éšªæè¿°**ï¼šçµ±ä¸€æ¶æ§‹å¯èƒ½å°è‡´æ€§èƒ½ä¸‹é™

**æ‡‰å°ç­–ç•¥**ï¼š
- æ·»åŠ æ€§èƒ½æ¸¬è©¦åŸºæº–
- ä½¿ç”¨ LRU ç·©å­˜
- ä¿ç•™å„ªåŒ–å¾Œçš„å¯¦ç¾

**å„ªå…ˆç´š**ï¼šP1

---

### é¢¨éšª3ï¼šå‘å¾Œå…¼å®¹æ€§ï¼ˆPhase 3ï¼‰

**é¢¨éšªæè¿°**ï¼šé‡æ§‹å¯èƒ½ç ´å£ç¾æœ‰ API

**æ‡‰å°ç­–ç•¥**ï¼š
- ä¿ç•™ç¾æœ‰æ–¹æ³•ç°½å
- æ·»åŠ å…¼å®¹æ€§æ¸¬è©¦
- æä¾›é·ç§»æ–‡æª”

**å„ªå…ˆç´š**ï¼šP0

---

## ğŸ“‹ æ¯æ—¥æª¢æŸ¥æ¸…å–®

### Phase 2 æ¯æ—¥æª¢æŸ¥
- [ ] IPA è¦å‰‡é…ç½®å®Œæ•´
- [ ] å–®å…ƒæ¸¬è©¦é€šéç‡ >95%
- [ ] æ–°è©æ³›åŒ–æ¸¬è©¦é€šé
- [ ] æ€§èƒ½æ¸¬è©¦ç„¡å›æ­¸
- [ ] æ–‡æª”æ›´æ–°åŒæ­¥

### Phase 3 æ¯æ—¥æª¢æŸ¥
- [ ] æŠ½è±¡æ¥å£æ¸…æ™°
- [ ] ä¸‰èªè¨€ä¸€è‡´æ€§é©—è­‰é€šé
- [ ] æ‰€æœ‰ç¾æœ‰æ¸¬è©¦é€šé
- [ ] ä»£ç¢¼è¦†è“‹ç‡ >90%
- [ ] æ€§èƒ½ç„¡å›æ­¸

### Phase 4 æ¯æ—¥æª¢æŸ¥
- [ ] æ—¥æ–‡æ¼¢å­—è®Šé«”æ­£ç¢º
- [ ] ä»£ç¢¼æ¸…ç†å®Œæˆ
- [ ] æ€§èƒ½å„ªåŒ–é”æ¨™
- [ ] æ–‡æª”æ›´æ–°å®Œæ•´

---

## ğŸ’¡ æˆåŠŸæ¨™æº–

### Phase 2 æˆåŠŸæ¨™æº–
- âœ… è‹±æ–‡æ¨¡çµ„å®Œå…¨åŸºæ–¼ IPA
- âœ… æ–°è©æ³›åŒ–èƒ½åŠ›é©—è­‰é€šé
- âœ… ç¬¦åˆã€ŒèªéŸ³ç¶­åº¦ã€æ ¸å¿ƒç†å¿µ
- âœ… æ–‡æª”æº–ç¢ºåæ˜ å¯¦ç¾

### Phase 3 æˆåŠŸæ¨™æº–
- âœ… ä¸‰èªè¨€ç¹¼æ‰¿çµ±ä¸€æŠ½è±¡
- âœ… å¼·åˆ¶æ¶æ§‹ä¸€è‡´æ€§
- âœ… æ˜“æ–¼æ·»åŠ æ–°èªè¨€
- âœ… çµ±ä¸€è®Šé«”è©•åˆ†æ©Ÿåˆ¶

### Phase 4 æˆåŠŸæ¨™æº–
- âœ… æ—¥æ–‡æ¼¢å­—è®Šé«”åŠŸèƒ½å®Œæ•´
- âœ… æ€§èƒ½æå‡ 30-50%
- âœ… ä»£ç¢¼è³ªé‡æå‡
- âœ… æŠ€è¡“å‚µå‹™æ¸›å°‘

---

**æ–‡æª”ç‰ˆæœ¬**ï¼šv1.0
**æœ€å¾Œæ›´æ–°**ï¼š2025-12-08
**ç¶­è­·è€…**ï¼šClaude Sonnet 4.5
**ç‹€æ…‹**ï¼šPhase 1 å®Œæˆï¼ŒPhase 2-4 å¾…åŸ·è¡Œ
