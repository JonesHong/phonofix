"""
æ€§èƒ½æ¸¬è©¦ï¼šé©—è­‰ LRU ç·©å­˜æ•ˆæœ (Task 7.3)

é©—æ”¶æ¨™æº–ï¼š
1. ç·©å­˜å‘½ä¸­ç‡ >80%
2. æ€§èƒ½æå‡ 30-50%
"""

import time
import pytest
from phonofix.languages.chinese.fuzzy_generator import ChineseFuzzyGenerator
from phonofix.languages.japanese.fuzzy_generator import JapaneseFuzzyGenerator
from phonofix.utils.cache import get_cache_stats, get_hit_rate, reset_cache_stats


class TestCachingPerformance:
    """æ¸¬è©¦ç·©å­˜æ€§èƒ½æå‡"""

    def test_chinese_phonetic_transform_cache_hit_rate(self):
        """æ¸¬è©¦ä¸­æ–‡ phonetic_transform ç·©å­˜å‘½ä¸­ç‡"""
        generator = ChineseFuzzyGenerator()

        # æ¸…é™¤ç·©å­˜å’Œçµ±è¨ˆ
        if hasattr(generator.phonetic_transform, 'cache_clear'):
            generator.phonetic_transform.cache_clear()
        reset_cache_stats()

        # æ¸¬è©¦è©å½™ï¼ˆæ¨¡æ“¬å¯¦éš›ä½¿ç”¨å ´æ™¯ï¼šé‡è¤‡æŸ¥è©¢ç›¸åŒè©å½™ï¼‰
        test_terms = ["å°åŒ—", "ç‰›å¥¶", "æ°¸å’Œè±†æ¼¿", "ç™¼æ®", "æ±äº¬"]

        # ç¬¬ä¸€è¼ªï¼šå…¨éƒ¨ cache miss
        for _ in range(10):
            for term in test_terms:
                generator.phonetic_transform(term)

        # æª¢æŸ¥ç·©å­˜å‘½ä¸­ç‡
        hit_rate = get_hit_rate("phonetic_transform")

        # å› ç‚ºæœ‰é‡è¤‡èª¿ç”¨ï¼Œå‘½ä¸­ç‡æ‡‰è©² >80%
        # è¨ˆç®—ï¼šç¬¬ä¸€æ¬¡ 5 å€‹è© missï¼Œå¾ŒçºŒ 9*5 æ¬¡å…¨éƒ¨ hit
        # å‘½ä¸­ç‡ = 45 / 50 = 90%
        assert hit_rate >= 0.80, f"ç·©å­˜å‘½ä¸­ç‡ä¸è¶³: {hit_rate:.2%} < 80%"

        print(f"\nâœ… phonetic_transform ç·©å­˜å‘½ä¸­ç‡: {hit_rate:.2%}")

    def test_chinese_generate_phonetic_variants_cache_hit_rate(self):
        """æ¸¬è©¦ä¸­æ–‡ generate_phonetic_variants ç·©å­˜å‘½ä¸­ç‡"""
        generator = ChineseFuzzyGenerator()

        # æ¸…é™¤ç·©å­˜å’Œçµ±è¨ˆ
        if hasattr(generator.generate_phonetic_variants, 'cache_clear'):
            generator.generate_phonetic_variants.cache_clear()
        reset_cache_stats()

        # æ¸¬è©¦ Pinyinï¼ˆæ¨¡æ“¬è®Šé«”ç”Ÿæˆå ´æ™¯ï¼‰
        test_pinyins = ["taibei", "niunai", "yonghe", "fahui", "dongjing"]

        # ç¬¬ä¸€è¼ªï¼šå…¨éƒ¨ cache miss
        for _ in range(10):
            for pinyin in test_pinyins:
                generator.generate_phonetic_variants(pinyin)

        # æª¢æŸ¥ç·©å­˜å‘½ä¸­ç‡
        hit_rate = get_hit_rate("generate_phonetic_variants")

        # å‘½ä¸­ç‡æ‡‰è©² >80%
        assert hit_rate >= 0.80, f"ç·©å­˜å‘½ä¸­ç‡ä¸è¶³: {hit_rate:.2%} < 80%"

        print(f"\nâœ… generate_phonetic_variants ç·©å­˜å‘½ä¸­ç‡: {hit_rate:.2%}")

    def test_chinese_generate_variants_performance_improvement(self):
        """æ¸¬è©¦ä¸­æ–‡ generate_variants æ€§èƒ½æå‡"""
        generator = ChineseFuzzyGenerator()

        # æ¸…é™¤ç·©å­˜
        if hasattr(generator.phonetic_transform, 'cache_clear'):
            generator.phonetic_transform.cache_clear()
        if hasattr(generator.generate_phonetic_variants, 'cache_clear'):
            generator.generate_phonetic_variants.cache_clear()

        test_terms = ["å°åŒ—è»Šç«™", "æ°¸å’Œè±†æ¼¿", "ç‰›å¥¶", "ç™¼æ®", "æ±äº¬"]

        # === æ¸¬è©¦ç„¡ç·©å­˜æ€§èƒ½ï¼ˆç¬¬ä¸€æ¬¡èª¿ç”¨ï¼‰===
        start_time = time.perf_counter()
        for term in test_terms:
            generator.generate_variants(term, max_variants=20)
        first_run_time = time.perf_counter() - start_time

        # === æ¸¬è©¦æœ‰ç·©å­˜æ€§èƒ½ï¼ˆé‡è¤‡èª¿ç”¨ï¼‰===
        start_time = time.perf_counter()
        for _ in range(10):
            for term in test_terms:
                generator.generate_variants(term, max_variants=20)
        repeated_run_time = time.perf_counter() - start_time

        # è¨ˆç®—å¹³å‡å–®æ¬¡èª¿ç”¨æ™‚é–“
        avg_first_run = first_run_time / len(test_terms)
        avg_repeated_run = repeated_run_time / (10 * len(test_terms))

        # æ€§èƒ½æå‡æ¯”ä¾‹
        improvement = (1 - avg_repeated_run / avg_first_run) * 100

        print(f"\nğŸ“Š æ€§èƒ½æ¸¬è©¦çµæœ:")
        print(f"   ç¬¬ä¸€æ¬¡èª¿ç”¨å¹³å‡æ™‚é–“: {avg_first_run*1000:.2f} ms")
        print(f"   ç·©å­˜å¾Œå¹³å‡æ™‚é–“: {avg_repeated_run*1000:.2f} ms")
        print(f"   æ€§èƒ½æå‡: {improvement:.1f}%")

        # é©—æ”¶æ¨™æº–ï¼šæ€§èƒ½æå‡ 30-50%
        assert improvement >= 30, f"æ€§èƒ½æå‡ä¸è¶³: {improvement:.1f}% < 30%"

        print(f"\nâœ… æ€§èƒ½æå‡é”æ¨™: {improvement:.1f}% >= 30%")

    @pytest.mark.skipif(True, reason="æ—¥æ–‡æ¸¬è©¦éœ€è¦ fugashi å’Œ cutlet ç³»çµ±å¥—ä»¶")
    def test_japanese_phonetic_transform_cache_hit_rate(self):
        """æ¸¬è©¦æ—¥æ–‡ phonetic_transform ç·©å­˜å‘½ä¸­ç‡"""
        generator = JapaneseFuzzyGenerator()

        # æ¸…é™¤ç·©å­˜å’Œçµ±è¨ˆ
        if hasattr(generator.phonetic_transform, 'cache_clear'):
            generator.phonetic_transform.cache_clear()
        reset_cache_stats()

        # æ¸¬è©¦è©å½™
        test_terms = ["æ±äº¬", "ä¼šç¤¾", "å­¦æ ¡", "å…ˆç”Ÿ", "æ™‚é–“"]

        # ç¬¬ä¸€è¼ªï¼šå…¨éƒ¨ cache miss
        for _ in range(10):
            for term in test_terms:
                generator.phonetic_transform(term)

        # æª¢æŸ¥ç·©å­˜å‘½ä¸­ç‡
        hit_rate = get_hit_rate("phonetic_transform")

        # å‘½ä¸­ç‡æ‡‰è©² >80%
        assert hit_rate >= 0.80, f"ç·©å­˜å‘½ä¸­ç‡ä¸è¶³: {hit_rate:.2%} < 80%"

        print(f"\nâœ… æ—¥æ–‡ phonetic_transform ç·©å­˜å‘½ä¸­ç‡: {hit_rate:.2%}")

    def test_cache_stats_api(self):
        """æ¸¬è©¦ç·©å­˜çµ±è¨ˆ API"""
        generator = ChineseFuzzyGenerator()

        # æ¸…é™¤ç·©å­˜å’Œçµ±è¨ˆ
        if hasattr(generator.phonetic_transform, 'cache_clear'):
            generator.phonetic_transform.cache_clear()
        reset_cache_stats()

        # åŸ·è¡Œä¸€äº›æ“ä½œ
        for _ in range(5):
            generator.phonetic_transform("å°åŒ—")
            generator.phonetic_transform("æ±äº¬")

        # ç²å–çµ±è¨ˆ
        stats = get_cache_stats()

        print(f"\nğŸ“Š ç·©å­˜çµ±è¨ˆ:")
        print(f"   ç¸½å‘½ä¸­ç‡: {stats.get('overall_hit_rate', 0):.2%}")
        print(f"   ç¸½å‘½ä¸­æ¬¡æ•¸: {stats.get('total_hits', 0)}")
        print(f"   ç¸½æœªå‘½ä¸­æ¬¡æ•¸: {stats.get('total_misses', 0)}")
        print(f"   ç¸½èª¿ç”¨æ¬¡æ•¸: {stats.get('total_calls', 0)}")

        # é©—è­‰çµ±è¨ˆæ­£ç¢ºï¼ˆåªçµ±è¨ˆæœ¬æ¸¬è©¦çš„èª¿ç”¨ï¼‰
        assert stats['total_calls'] == 10, f"ç¸½èª¿ç”¨æ¬¡æ•¸æ‡‰è©²æ˜¯ 10ï¼Œå¯¦éš›æ˜¯ {stats['total_calls']}"
        assert stats['total_hits'] >= 8, f"æ‡‰è©²æœ‰è‡³å°‘ 8 æ¬¡å‘½ä¸­ï¼Œå¯¦éš›æ˜¯ {stats['total_hits']}"

        print(f"\nâœ… ç·©å­˜çµ±è¨ˆ API æ­£å¸¸å·¥ä½œ")


class TestCacheCorrectness:
    """æ¸¬è©¦ç·©å­˜ä¸å½±éŸ¿åŠŸèƒ½æ­£ç¢ºæ€§"""

    def test_chinese_cache_returns_same_results(self):
        """æ¸¬è©¦ä¸­æ–‡ç·©å­˜è¿”å›ç›¸åŒçµæœ"""
        generator = ChineseFuzzyGenerator()

        # æ¸…é™¤ç·©å­˜å’Œçµ±è¨ˆ
        if hasattr(generator.phonetic_transform, 'cache_clear'):
            generator.phonetic_transform.cache_clear()
        reset_cache_stats()

        term = "å°åŒ—"

        # ç¬¬ä¸€æ¬¡èª¿ç”¨ï¼ˆcache missï¼‰
        result1 = generator.phonetic_transform(term)

        # ç¬¬äºŒæ¬¡èª¿ç”¨ï¼ˆcache hitï¼‰
        result2 = generator.phonetic_transform(term)

        # çµæœæ‡‰è©²å®Œå…¨ç›¸åŒ
        assert result1 == result2, "ç·©å­˜çµæœèˆ‡åŸå§‹çµæœä¸ä¸€è‡´"

        print(f"\nâœ… ç·©å­˜çµæœæ­£ç¢º: {result1} == {result2}")

    @pytest.mark.skipif(True, reason="æ—¥æ–‡æ¸¬è©¦éœ€è¦ fugashi å’Œ cutlet ç³»çµ±å¥—ä»¶")
    def test_japanese_cache_returns_same_results(self):
        """æ¸¬è©¦æ—¥æ–‡ç·©å­˜è¿”å›ç›¸åŒçµæœ"""
        generator = JapaneseFuzzyGenerator()

        # æ¸…é™¤ç·©å­˜å’Œçµ±è¨ˆ
        if hasattr(generator.phonetic_transform, 'cache_clear'):
            generator.phonetic_transform.cache_clear()
        reset_cache_stats()

        term = "æ±äº¬"

        # ç¬¬ä¸€æ¬¡èª¿ç”¨ï¼ˆcache missï¼‰
        result1 = generator.phonetic_transform(term)

        # ç¬¬äºŒæ¬¡èª¿ç”¨ï¼ˆcache hitï¼‰
        result2 = generator.phonetic_transform(term)

        # çµæœæ‡‰è©²å®Œå…¨ç›¸åŒ
        assert result1 == result2, "ç·©å­˜çµæœèˆ‡åŸå§‹çµæœä¸ä¸€è‡´"

        print(f"\nâœ… æ—¥æ–‡ç·©å­˜çµæœæ­£ç¢º: {result1} == {result2}")

    def test_cache_with_different_inputs(self):
        """æ¸¬è©¦ç·©å­˜æ­£ç¢ºå€åˆ†ä¸åŒè¼¸å…¥"""
        generator = ChineseFuzzyGenerator()

        # æ¸…é™¤ç·©å­˜å’Œçµ±è¨ˆ
        if hasattr(generator.phonetic_transform, 'cache_clear'):
            generator.phonetic_transform.cache_clear()
        reset_cache_stats()

        # ä¸åŒçš„è¼¸å…¥æ‡‰è©²æœ‰ä¸åŒçš„ç·©å­˜
        result_taipei = generator.phonetic_transform("å°åŒ—")
        result_milk = generator.phonetic_transform("ç‰›å¥¶")

        assert result_taipei != result_milk, "ä¸åŒè¼¸å…¥æ‡‰è©²æœ‰ä¸åŒçµæœ"

        # é‡è¤‡èª¿ç”¨æ‡‰è©²è¿”å›ç›¸åŒçµæœ
        assert generator.phonetic_transform("å°åŒ—") == result_taipei
        assert generator.phonetic_transform("ç‰›å¥¶") == result_milk

        print(f"\nâœ… ç·©å­˜æ­£ç¢ºå€åˆ†ä¸åŒè¼¸å…¥: {result_taipei} != {result_milk}")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
